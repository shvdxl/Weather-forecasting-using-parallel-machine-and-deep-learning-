{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed5a8fd-abf0-4b4f-8728-a2693d3c84a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.1%2Bcu118-cp38-cp38-linux_x86_64.whl (2325.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m771.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp38-cp38-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch) (3.0.3)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting triton==2.1.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torch) (2022.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.8/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->torchvision) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.8/site-packages (from requests->torchvision) (1.26.8)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, filelock, triton, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.9.0 mpmath-1.3.0 sympy-1.12 torch-2.1.1+cu118 torchaudio-2.1.1+cu118 torchvision-0.16.1+cu118 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ecaa090-9b09-4943-81d0-6bdc2aa6b82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multigpu_weatheraus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multigpu_weatheraus.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datautils import MyTrainDataset\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rank: Unique identifier of each process\n",
    "        world_size: Total number of processes\n",
    "    \"\"\"\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        gpu_id: int,\n",
    "        save_every: int,\n",
    "    ) -> None:\n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.save_every = save_every\n",
    "        self.model = DDP(model, device_ids=[gpu_id])\n",
    "\n",
    "    def _run_batch(self, source, targets):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        b_sz = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n",
    "        self.train_data.sampler.set_epoch(epoch)\n",
    "        for source, targets in self.train_data:\n",
    "            source = source.to(self.gpu_id)\n",
    "            targets = targets.to(self.gpu_id)\n",
    "            self._run_batch(source, targets)\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        ckp = self.model.module.state_dict()\n",
    "        PATH = \"checkpoint_multigpu4.pt\"\n",
    "        torch.save(ckp, PATH)\n",
    "        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "            if self.gpu_id == 0 and epoch % self.save_every == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "                print(\"self.save_every\" ,  self.save_every)\n",
    "                print('save at epoch' , epoch)\n",
    "\n",
    "class Net(nn.Module):    # class Net will be the subclass of torch.nn.Module ie Class Net --EXTENDS--> Class nn.Module\n",
    "    def __init__(self, n_features):    # initialize the layers you want to use in this function/method\n",
    "        super(Net, self).__init__()    # call to init method of superclass ie nn.Module\n",
    "        self.fc1 = nn.Linear(n_features, 15)    # Input Layer of n_features input nodes to 5 outputs\n",
    "        self.fc2 = nn.Linear(15, 3)             # 1st Hidden Layer of 5 nodes to 3 outputs\n",
    "        self.fc3 = nn.Linear(3, 1)             # 2st Hidden Layer of 3 nodes to 1 output\n",
    "    \n",
    "    def forward(self, x):              # Feed Forward\n",
    "        x = F.relu(self.fc1(x))        # torch.nn.functional.relu() ie a Activation Function \n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)) \n",
    "    \n",
    "def load_train_objs():\n",
    "    # train_set = MyTrainDataset(2048)  # load your dataset\n",
    "    df = pd.read_csv(\"weatherAUS.csv\")\n",
    "    df = df[['Rainfall','Humidity3pm','RainToday','Pressure9am','RainTomorrow']]\n",
    "    df = df.dropna(how = 'any')\n",
    "    df.shape\n",
    "\n",
    "    df.RainToday[df.RainToday == 'Yes'] = 1 \n",
    "    df.RainToday[df.RainToday == 'No'] = 0\n",
    "    df.RainToday = pd.to_numeric(df.RainToday)\n",
    "    df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
    "    df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
    "    df.RainTomorrow = pd.to_numeric(df.RainTomorrow)\n",
    "    df.info()\n",
    "\n",
    "    Y, X = df[['RainTomorrow']], df.drop('RainTomorrow', axis = 1, inplace = False)\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "    # input must be numeric\n",
    "    Xtrain = torch.from_numpy(Xtrain.to_numpy()).float()\n",
    "    Xtest = torch.from_numpy(Xtest.to_numpy()).float()\n",
    "    Ytrain = torch.from_numpy(Ytrain.to_numpy()).float()\n",
    "    Ytest = torch.squeeze(torch.from_numpy(Ytest.to_numpy()).float())    \n",
    "\n",
    "    # Create TensorDataset\n",
    "    train_set = TensorDataset(Xtrain, Ytrain)\n",
    "    test_dataset = TensorDataset(Xtest, Ytest)\n",
    "\n",
    "    # model = torch.nn.Linear(20, 1)  # load your model\n",
    "    model = Net(Xtrain.shape[1])\n",
    "    \n",
    "    \n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr = 10 **(-4))\n",
    "    return train_set, model, optimizer\n",
    "\n",
    "\n",
    "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        sampler=DistributedSampler(dataset)\n",
    "    )\n",
    "\n",
    "\n",
    "def main(rank: int, world_size: int, save_every: int, total_epochs: int, batch_size: int):\n",
    "    ddp_setup(rank, world_size)\n",
    "    dataset, model, optimizer = load_train_objs()\n",
    "    train_data = prepare_dataloader(dataset, batch_size)\n",
    "    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n",
    "    trainer.train(total_epochs)\n",
    "    destroy_process_group()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='simple distributed training job')\n",
    "    parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')\n",
    "    parser.add_argument('save_every', type=int, help='How often to save a snapshot')\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b539a9fa-d136-41b1-952f-69f21cefea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W socket.cpp:663] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\n",
      "/dli/task/multigpu_weatheraus.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "/dli/task/multigpu_weatheraus.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "/dli/task/multigpu_weatheraus.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "/dli/task/multigpu_weatheraus.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "/dli/task/multigpu_weatheraus.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "/dli/task/multigpu_weatheraus.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "/dli/task/multigpu_weatheraus.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "[GPU2] Epoch 0 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 0 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 0 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 0 | Batchsize: 64 | Steps: 390\n",
      "Epoch 0 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 0\n",
      "[GPU1] Epoch 1 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 1 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 1 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 1 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 2 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 2 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 2 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 2 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 3 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 3 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 3 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 3 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 4 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 4 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 4 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 4 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 5 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 5 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 5 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 5 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 6 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 6 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 6 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 6 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 7 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 7 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 7 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 7 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 8 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 8 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 8 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 8 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 9 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 9 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 9 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 9 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 10 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 10 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 10 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 10 | Batchsize: 64 | Steps: 390\n",
      "Epoch 10 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 10\n",
      "[GPU3] Epoch 11 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 11 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 11 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 11 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 12 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 12 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 12 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 12 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 13 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 13 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 13 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 13 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 14 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 14 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 14 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 14 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 15 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 15 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 15 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 15 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 16 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 16 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 16 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 16 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 17 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 17 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 17 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 17 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 18 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 18 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 18 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 18 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 19 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 19 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 19 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 19 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 20 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 20 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 20 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 20 | Batchsize: 64 | Steps: 390\n",
      "Epoch 20 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 20\n",
      "[GPU3] Epoch 21 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 21 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 21 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 21 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 22 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 22 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 22 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 22 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 23 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 23 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 23 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 23 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 24 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 24 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 24 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 24 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 25 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 25 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 25 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 25 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 26 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 26 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 26 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 26 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 27 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 27 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 27 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 27 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 28 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 28 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 28 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 28 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 29 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 29 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 29 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 29 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 30 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 30 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 30 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 30 | Batchsize: 64 | Steps: 390\n",
      "Epoch 30 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 30\n",
      "[GPU3] Epoch 31 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 31 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 31 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 31 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 32 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 32 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 32 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 32 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 33 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 33 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 33 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 33 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 34 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 34 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 34 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 34 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 35 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 35 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 35 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 35 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 36 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 36 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 36 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 36 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 37 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 37 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 37 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 37 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 38 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 38 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 38 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 38 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 39 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 39 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 39 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 39 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 40 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 40 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 40 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 40 | Batchsize: 64 | Steps: 390\n",
      "Epoch 40 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 40\n",
      "[GPU1] Epoch 41 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 41 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 41 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 41 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 42 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 42 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 42 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 42 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 43 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 43 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 43 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 43 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 44 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 44 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 44 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 44 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 45 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 45 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 45 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 45 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 46 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 46 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 46 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 46 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 47 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 47 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 47 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 47 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 48 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 48 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 48 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 48 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 49 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 49 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 49 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 49 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 50 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 50 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 50 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 50 | Batchsize: 64 | Steps: 390\n",
      "Epoch 50 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 50\n",
      "[GPU1] Epoch 51 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 51 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 51 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 51 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 52 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 52 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 52 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 52 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 53 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 53 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 53 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 53 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 54 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 54 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 54 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 54 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 55 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 55 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 55 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 55 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 56 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 56 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 56 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 56 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 57 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 57 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 57 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 57 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 58 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 58 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 58 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 58 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 59 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 59 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 59 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 59 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 60 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 60 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 60 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 60 | Batchsize: 64 | Steps: 390\n",
      "Epoch 60 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 60\n",
      "[GPU3] Epoch 61 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 61 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 61 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 61 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 62 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 62 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 62 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 62 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 63 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 63 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 63 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 63 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 64 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 64 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 64 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 64 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 65 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 65 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 65 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 65 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 66 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 66 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 66 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 66 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 67 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 67 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 67 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 67 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 68 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 68 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 68 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 68 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 69 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 69 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 69 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 69 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 70 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 70 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 70 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 70 | Batchsize: 64 | Steps: 390\n",
      "Epoch 70 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 70\n",
      "[GPU1] Epoch 71 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 71 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 71 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 71 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 72 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 72 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 72 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 72 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 73 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 73 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 73 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 73 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 74 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 74 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 74 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 74 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 75 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 75 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 75 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 75 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 76 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 76 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 76 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 76 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 77 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 77 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 77 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 77 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 78 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 78 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 78 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 78 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 79 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 79 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 79 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 79 | Batchsize: 64 | Steps: 390\n",
      "[GPU2] Epoch 80 | Batchsize: 64 | Steps: 390\n",
      "[GPU3] Epoch 80 | Batchsize: 64 | Steps: 390\n",
      "[GPU1] Epoch 80 | Batchsize: 64 | Steps: 390\n",
      "[GPU0] Epoch 80 | Batchsize: 64 | Steps: 390\n",
      "Epoch 80 | Training checkpoint saved at checkpoint_multigpu4.pt\n",
      "self.save_every 10\n",
      "save at epoch 80\n",
      "CPU times: user 815 ms, sys: 253 ms, total: 1.07 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python multigpu_weatheraus.py 81 10 --batch_size 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005cebb-02f1-4ed5-b255-f70cd3e9cc02",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5490ac7-5276-4458-b322-450a4234c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2113590087.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/tmp/ipykernel_158/2113590087.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "/tmp/ipykernel_158/2113590087.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "checkpoint_multigpu3.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.00      0.00      0.00     19361\n",
      "        Rain       0.22      1.00      0.37      5577\n",
      "\n",
      "    accuracy                           0.22     24938\n",
      "   macro avg       0.11      0.50      0.18     24938\n",
      "weighted avg       0.05      0.22      0.08     24938\n",
      "\n",
      "checkpoint_singleGPU.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.78      1.00      0.87     19361\n",
      "        Rain       0.00      0.00      0.00      5577\n",
      "\n",
      "    accuracy                           0.78     24938\n",
      "   macro avg       0.39      0.50      0.44     24938\n",
      "weighted avg       0.60      0.78      0.68     24938\n",
      "\n",
      "checkpoint_new.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.78      1.00      0.87     19361\n",
      "        Rain       0.00      0.00      0.00      5577\n",
      "\n",
      "    accuracy                           0.78     24938\n",
      "   macro avg       0.39      0.50      0.44     24938\n",
      "weighted avg       0.60      0.78      0.68     24938\n",
      "\n",
      "checkpoint.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.00      0.00      0.00     19361\n",
      "        Rain       0.22      1.00      0.37      5577\n",
      "\n",
      "    accuracy                           0.22     24938\n",
      "   macro avg       0.11      0.50      0.18     24938\n",
      "weighted avg       0.05      0.22      0.08     24938\n",
      "\n",
      "checkpoint_multigpu4.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.78      1.00      0.87     19361\n",
      "        Rain       0.00      0.00      0.00      5577\n",
      "\n",
      "    accuracy                           0.78     24938\n",
      "   macro avg       0.39      0.50      0.44     24938\n",
      "weighted avg       0.60      0.78      0.68     24938\n",
      "\n",
      "checkpoint_multigpu2.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.78      1.00      0.87     19361\n",
      "        Rain       0.00      0.00      0.00      5577\n",
      "\n",
      "    accuracy                           0.78     24938\n",
      "   macro avg       0.39      0.50      0.44     24938\n",
      "weighted avg       0.60      0.78      0.68     24938\n",
      "\n",
      "checkpoint_multigpu.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.00      0.00      0.00     19361\n",
      "        Rain       0.22      1.00      0.37      5577\n",
      "\n",
      "    accuracy                           0.22     24938\n",
      "   macro avg       0.11      0.50      0.18     24938\n",
      "weighted avg       0.05      0.22      0.08     24938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch, glob\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import warnings\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "df = df[['Rainfall','Humidity3pm','RainToday','Pressure9am','RainTomorrow']]\n",
    "df = df.dropna(how = 'any')\n",
    "df.shape\n",
    "\n",
    "df.RainToday[df.RainToday == 'Yes'] = 1 \n",
    "df.RainToday[df.RainToday == 'No'] = 0\n",
    "df.RainToday = pd.to_numeric(df.RainToday)\n",
    "df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
    "df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
    "df.RainTomorrow = pd.to_numeric(df.RainTomorrow)\n",
    "df.info()\n",
    "\n",
    "Y, X = df[['RainTomorrow']], df.drop('RainTomorrow', axis = 1, inplace = False)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "Xtest = torch.from_numpy(Xtest.to_numpy()).float()\n",
    "\n",
    "class Net(nn.Module):    # class Net will be the subclass of torch.nn.Module ie Class Net --EXTENDS--> Class nn.Module\n",
    "    def __init__(self, n_features):    # initialize the layers you want to use in this function/method\n",
    "        super(Net, self).__init__()    # call to init method of superclass ie nn.Module\n",
    "        self.fc1 = nn.Linear(n_features, 15)    # Input Layer of n_features input nodes to 5 outputs\n",
    "        self.fc2 = nn.Linear(15, 3)             # 1st Hidden Layer of 5 nodes to 3 outputs\n",
    "        self.fc3 = nn.Linear(3, 1)             # 2st Hidden Layer of 3 nodes to 1 output\n",
    "    \n",
    "    def forward(self, x):              # Feed Forward\n",
    "        x = F.relu(self.fc1(x))        # torch.nn.functional.relu() ie a Activation Function \n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)) \n",
    "files = []\n",
    "files += glob.glob('checkpoint*.pt')\n",
    "# files += glob.glob('my_model*.pth')\n",
    "\n",
    "for model_file in files:\n",
    "    \n",
    "    net = Net(Xtrain.shape[1])\n",
    "    state_dict = torch.load(model_file)\n",
    "\n",
    "    # Remove the \"module.\" prefix from the keys in the state dictionary\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "    # Load the modified state dictionary\n",
    "    net.load_state_dict(state_dict)\n",
    "    net.eval()\n",
    "\n",
    "\n",
    "    classes = ['No rain', 'Rain']\n",
    "\n",
    "    y_test = torch.squeeze(torch.from_numpy(Ytest.to_numpy()).float()) \n",
    "\n",
    "    y_pred = net(Xtest)\n",
    "    y_pred\n",
    "    # Convert the probabilities to binary classes ie (1 or 0) and (True or False) by the help of threshold values\n",
    "    y_pred = y_pred.ge(.5).view(-1).cpu() # test on cpu ?? yes\n",
    "    y_pred\n",
    "\n",
    "    y_test = y_test.cpu()\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(f'{model_file}')\n",
    "    print(classification_report(y_test, y_pred, target_names = classes))  \n",
    "    del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79c3438-2902-464d-9cab-de7daa96c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing signlegpu_weatheraus.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile signlegpu_weatheraus.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datautils import MyTrainDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datautils import MyTrainDataset\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        gpu_id: int,\n",
    "        save_every: int, \n",
    "    ) -> None:\n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.optimizer = optimizer\n",
    "        self.save_every = save_every\n",
    "\n",
    "    def _run_batch(self, source, targets):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        b_sz = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n",
    "        for source, targets in self.train_data:\n",
    "            source = source.to(self.gpu_id)\n",
    "            targets = targets.to(self.gpu_id)\n",
    "            self._run_batch(source, targets)\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        ckp = self.model.state_dict()\n",
    "        PATH = \"checkpoint_singleGPU.pt\" #here ? yes\n",
    "        torch.save(ckp, PATH)\n",
    "        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "            if epoch % self.save_every == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "\n",
    "\n",
    "class Net(nn.Module):    # class Net will be the subclass of torch.nn.Module ie Class Net --EXTENDS--> Class nn.Module\n",
    "    def __init__(self, n_features):    # initialize the layers you want to use in this function/method\n",
    "        super(Net, self).__init__()    # call to init method of superclass ie nn.Module\n",
    "        self.fc1 = nn.Linear(n_features, 15)    # Input Layer of n_features input nodes to 5 outputs\n",
    "        self.fc2 = nn.Linear(15, 3)             # 1st Hidden Layer of 5 nodes to 3 outputs\n",
    "        self.fc3 = nn.Linear(3, 1)             # 2st Hidden Layer of 3 nodes to 1 output\n",
    "    \n",
    "    def forward(self, x):              # Feed Forward\n",
    "        x = F.relu(self.fc1(x))        # torch.nn.functional.relu() ie a Activation Function \n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)) \n",
    "    \n",
    "def load_train_objs():\n",
    "     # train_set = MyTrainDataset(2048)  # load your dataset\n",
    "    df = pd.read_csv(\"weatherAUS.csv\")\n",
    "    df = df[['Rainfall','Humidity3pm','RainToday','Pressure9am','RainTomorrow']]\n",
    "    df = df.dropna(how = 'any')\n",
    "    df.shape\n",
    "\n",
    "    df.RainToday[df.RainToday == 'Yes'] = 1 \n",
    "    df.RainToday[df.RainToday == 'No'] = 0\n",
    "    df.RainToday = pd.to_numeric(df.RainToday)\n",
    "    df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
    "    df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
    "    df.RainTomorrow = pd.to_numeric(df.RainTomorrow)\n",
    "    df.info()\n",
    "\n",
    "    Y, X = df[['RainTomorrow']], df.drop('RainTomorrow', axis = 1, inplace = False)\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "    # input must be numeric\n",
    "    Xtrain = torch.from_numpy(Xtrain.to_numpy()).float()\n",
    "    Xtest = torch.from_numpy(Xtest.to_numpy()).float()\n",
    "    Ytrain = torch.from_numpy(Ytrain.to_numpy()).float()\n",
    "    Ytest = torch.squeeze(torch.from_numpy(Ytest.to_numpy()).float())    \n",
    "\n",
    "    # Create TensorDataset\n",
    "    train_set = TensorDataset(Xtrain, Ytrain)\n",
    "    test_dataset = TensorDataset(Xtest, Ytest)\n",
    "\n",
    "    # model = torch.nn.Linear(20, 1)  # load your model\n",
    "    model = Net(Xtrain.shape[1])\n",
    "    \n",
    "    \n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),  lr = 10 **(-4))\n",
    "    return train_set, model, optimizer\n",
    "\n",
    "\n",
    "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "def main(device, total_epochs, save_every, batch_size):\n",
    "    dataset, model, optimizer = load_train_objs()\n",
    "    train_data = prepare_dataloader(dataset, batch_size)\n",
    "    trainer = Trainer(model, train_data, optimizer, device, save_every)\n",
    "    trainer.train(total_epochs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='simple distributed training job')\n",
    "    parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')\n",
    "    parser.add_argument('save_every', type=int, help='How often to save a snapshot')\n",
    "    parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    device = 0  # shorthand for cuda:0\n",
    "    main(device, args.total_epochs, args.save_every, args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25726f2b-e8be-4e51-95c9-b757238a394b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signlegpu_weatheraus.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "signlegpu_weatheraus.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "signlegpu_weatheraus.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "[GPU0] Epoch 0 | Batchsize: 128 | Steps: 780\n",
      "Epoch 0 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 1 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 2 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 3 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 4 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 5 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 6 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 7 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 8 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 9 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 10 | Batchsize: 128 | Steps: 780\n",
      "Epoch 10 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 11 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 12 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 13 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 14 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 15 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 16 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 17 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 18 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 19 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 20 | Batchsize: 128 | Steps: 780\n",
      "Epoch 20 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 21 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 22 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 23 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 24 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 25 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 26 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 27 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 28 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 29 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 30 | Batchsize: 128 | Steps: 780\n",
      "Epoch 30 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 31 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 32 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 33 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 34 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 35 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 36 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 37 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 38 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 39 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 40 | Batchsize: 128 | Steps: 780\n",
      "Epoch 40 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 41 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 42 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 43 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 44 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 45 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 46 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 47 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 48 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 49 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 50 | Batchsize: 128 | Steps: 780\n",
      "Epoch 50 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 51 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 52 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 53 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 54 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 55 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 56 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 57 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 58 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 59 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 60 | Batchsize: 128 | Steps: 780\n",
      "Epoch 60 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 61 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 62 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 63 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 64 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 65 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 66 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 67 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 68 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 69 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 70 | Batchsize: 128 | Steps: 780\n",
      "Epoch 70 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "[GPU0] Epoch 71 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 72 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 73 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 74 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 75 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 76 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 77 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 78 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 79 | Batchsize: 128 | Steps: 780\n",
      "[GPU0] Epoch 80 | Batchsize: 128 | Steps: 780\n",
      "Epoch 80 | Training checkpoint saved at checkpoint_singleGPU.pt\n",
      "CPU times: user 1.12 s, sys: 433 ms, total: 1.55 s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python signlegpu_weatheraus.py 81 10 --batch_size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f76e0-44a1-4b1b-8afe-4b72fc9fb6cc",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ee18013-4989-477b-9471-f453f1f7d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/146710385.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainToday[df.RainToday == 'No'] = 0\n",
      "/tmp/ipykernel_158/146710385.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
      "/tmp/ipykernel_158/146710385.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124689 entries, 0 to 145458\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Rainfall      124689 non-null  float64\n",
      " 1   Humidity3pm   124689 non-null  float64\n",
      " 2   RainToday     124689 non-null  int64  \n",
      " 3   Pressure9am   124689 non-null  float64\n",
      " 4   RainTomorrow  124689 non-null  int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 5.7 MB\n",
      "checkpoint_singleGPU.pt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No rain       0.78      1.00      0.87     19361\n",
      "        Rain       0.00      0.00      0.00      5577\n",
      "\n",
      "    accuracy                           0.78     24938\n",
      "   macro avg       0.39      0.50      0.44     24938\n",
      "weighted avg       0.60      0.78      0.68     24938\n",
      "\n",
      "corrctcount:19361\n",
      "wrongcount:5577\n",
      "Accuracy Test :77.63653861576711\n"
     ]
    }
   ],
   "source": [
    "import torch, glob\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import warnings\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "df = df[['Rainfall','Humidity3pm','RainToday','Pressure9am','RainTomorrow']]\n",
    "df = df.dropna(how = 'any')\n",
    "df.shape\n",
    "\n",
    "df.RainToday[df.RainToday == 'Yes'] = 1 \n",
    "df.RainToday[df.RainToday == 'No'] = 0\n",
    "df.RainToday = pd.to_numeric(df.RainToday)\n",
    "df.RainTomorrow[df.RainTomorrow == 'Yes'] = 1\n",
    "df.RainTomorrow[df.RainTomorrow == 'No'] = 0\n",
    "df.RainTomorrow = pd.to_numeric(df.RainTomorrow)\n",
    "df.info()\n",
    "\n",
    "Y, X = df[['RainTomorrow']], df.drop('RainTomorrow', axis = 1, inplace = False)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "Xtest = torch.from_numpy(Xtest.to_numpy()).float()\n",
    "\n",
    "class Net(nn.Module):    # class Net will be the subclass of torch.nn.Module ie Class Net --EXTENDS--> Class nn.Module\n",
    "    def __init__(self, n_features):    # initialize the layers you want to use in this function/method\n",
    "        super(Net, self).__init__()    # call to init method of superclass ie nn.Module\n",
    "        self.fc1 = nn.Linear(n_features, 15)    # Input Layer of n_features input nodes to 5 outputs\n",
    "        self.fc2 = nn.Linear(15, 3)             # 1st Hidden Layer of 5 nodes to 3 outputs\n",
    "        self.fc3 = nn.Linear(3, 1)             # 2st Hidden Layer of 3 nodes to 1 output\n",
    "    \n",
    "    def forward(self, x):              # Feed Forward\n",
    "        x = F.relu(self.fc1(x))        # torch.nn.functional.relu() ie a Activation Function \n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)) \n",
    "files = []\n",
    "files += glob.glob('checkpoint_singleGPU*.pt') # here i think there could be wrong , not wrong\n",
    "# files += glob.glob('my_model*.pth')\n",
    "\n",
    "for model_file in files:\n",
    "    \n",
    "    net = Net(Xtrain.shape[1])\n",
    "    state_dict = torch.load(model_file)\n",
    "\n",
    "    # Remove the \"module.\" prefix from the keys in the state dictionary\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "    # Load the modified state dictionary\n",
    "    net.load_state_dict(state_dict)\n",
    "    net.eval()\n",
    "\n",
    "    classes = ['No rain', 'Rain']\n",
    "\n",
    "    y_test = torch.squeeze(torch.from_numpy(Ytest.to_numpy()).float()) \n",
    "\n",
    "    y_pred = net(Xtest)\n",
    "    y_pred\n",
    "    # Convert the probabilities to binary classes ie (1 or 0) and (True or False) by the help of threshold values\n",
    "    y_pred = y_pred.ge(.5).view(-1).cpu() # test on cpu ?? yes\n",
    "    y_pred\n",
    "\n",
    "    y_test = y_test.cpu()\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(f'{model_file}')\n",
    "    print(classification_report(y_test, y_pred, target_names = classes))  \n",
    "    \n",
    "    corrctcount = wrongcount = 0\n",
    "    for i , (target, pred) in enumerate(zip(y_test,y_pred)):\n",
    "        # print(f'target:{bool(target)} , pred:{pred}')\n",
    "        # if i > 100 : break\n",
    "        \n",
    "        if bool(target)==pred:\n",
    "            corrctcount+=1\n",
    "        else:\n",
    "            wrongcount+=1\n",
    "    \n",
    "    print(f'corrctcount:{corrctcount}')\n",
    "    print(f'wrongcount:{wrongcount}')\n",
    "    print(f'Accuracy Test :{ (corrctcount/( corrctcount + wrongcount)) *100 }')\n",
    "        \n",
    "    del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de0f5e-e652-4ebb-a99d-2d104ad149b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
